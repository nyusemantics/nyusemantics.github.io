<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Stone, NYU Semantics Group, Fall 2016</title>

    <link rel="stylesheet" href="../stylesheets/styles.css">
    <link rel="stylesheet" href="../stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>

  <body>
    <div class="wrapper abstract">
      <h1>Interpreting Multimodal Communicative Action</h1>
      <h2>Matthew Stone, Rutgers</h2>
      <h3>Abstract</h3>
      <p class="view">
      I give a short tutorial overview of the nonverbal actions that speakers use to enrich the meanings of their contributions to spoken face-to-face conversation. We will see the ways speakers not only refer to real space but construct virtual and abstract spaces to locate events; the ways they indicate geometry, represent objects and imitate actions; and the consistent patterns that link successive gestures into extended depictions. Time permitting, we will also explore the analogous ways speakers can recruit physical props and practical activity in the service of communication. Finally, we will look at some of the formal devices that have been used to model the compositional connections between language and gesture, including generalized conjunction, function-argument dependencies and the reconstruction of implicit inferential relationships. A key theme throughout the presentation will be the role of discourse coherence in organizing content across modalities into an integrated whole.
      </p>
    </div>
    <script src="javascripts/scale.fix.js"></script>
  </body>
</head>
